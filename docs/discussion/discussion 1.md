# 第一次讨论
# 项目名称
MR for oculus
# 项目描述
使用unity建立一套基于手势识别的MR交互系统。主要功能：
* 基于手势的UI交互：手掌打开呼出菜单，poke点击按钮
* 计划开发两个模式：正常模式和我的MR应用，第一个是在正常桌面环境下使用手势交互，第二种是MR模式，MR模式将会使用两个正常彩色摄像头作为外设来创造透明效果，在MR模式中，可以打开创建的各种应用。应用包括独占模式和窗口模式。窗口模式不一定显示窗口，但支持同时几个应用显示在场景中，比如左边是电脑屏幕，而右边是摆放的3D模型；独占模式主要用于VR应用（不一定要写，但应该预留出这么一个模式）
* 直接用手对3D模型进行控制，不同形式的拖拽、握动作来进行平移、旋转、缩放、添加辅助线等操作
* （可选）改变原有系统VR应用程序的交互方式，可以用手代替手柄玩原先安装好的各种游戏。这里ray的方向和食指方向相同，pinch实现点击，当然也要支持poke操作
# 主要问题
* MR模式中，如何把得到的左右眼像素信息加入场景，并在场景中添加物体？unity中两个摄像头是直接得到的原3D场景中的图像，难道需要把原来的3D场景换成真实世界中的场景？（解决方向：查AR相关文档，或许里面有专门的解决办法）
* 屏幕共享中得到的是数据流，那么将它们转化成像素信息后如何在3D场景中渲染？如何做到快速？因为可能场景中有不只一个设备屏幕
* （针对可选项）unity程序如何即可以在作为VR应用在虚拟场景下工作，又可以在后台运行，仅负责手势的识别和交互？
# 讨论结果
* 只设置独占模式，3D模型等都放到独占模式中，因为原系统UI的交互很难改变，且意义不大。
* 不一定使用视频流，调研其他远程控制方式。
* 透视效果不一定要实现。（补充：黑白透视效果后来已经知道怎么实现了，在unity中可以直接设置）。
* 要尽可能体现手势控制的易用性，高效率则不一定可以实现。
* 可以像无人船那样搭建一个可以实时监视和控制的3D模型，它和真实的物理世界挂钩，如三教模型。
* 本项目的其他一些重要的点，在调研报告中会写到。